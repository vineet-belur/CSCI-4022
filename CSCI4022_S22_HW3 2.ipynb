{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='top'></a>\n",
    "\n",
    "# CSCI4022 Homework 3; K-Means\n",
    "\n",
    "## Due Friday, February 11 at 11:59 pm to Canvas and Gradescope\n",
    "\n",
    "#### Submit this file as a .ipynb with *all cells compiled and run* to the associated dropbox.\n",
    "\n",
    "***\n",
    "\n",
    "Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Here is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.  I also recommend the [wikibook](https://en.wikibooks.org/wiki/LaTeX) for LaTex.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do **Kernel $\\rightarrow$ Restart & Run All** as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 45 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm.\n",
    "- There are two ways to quickly make a .pdf out of this notebook for Gradescope submission.  Either:\n",
    " - Use File -> Download as PDF via LaTeX.  This will require your system path find a working install of a TeX compiler\n",
    " - Easier: Use File ->  Print Preview, and then Right-Click -> Print using your default browser and \"Print to PDF\"\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) |\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p1'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 1 (Theory: Distance Setup; 5 pts)\n",
    "\n",
    "In the later portion we're going to combine two distance measures by creating an average of them.  Is this valid?\n",
    "\n",
    "Prove the following:\n",
    "\n",
    "If $f(x,y)$ and $g(x,y)$ are both valid distance measures mapping objects $x,y$ from *some* space to $\\mathbb{R}^+$, prove that $h(x,y)=a\\cdot f(x,y) + b g(x,y)$ is also a valid distance measure for positive integers $a$ and $b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p2'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 2 (K-Means and Initialization; 22 pts)\n",
    "\n",
    "In the next two problems we cluster the Pok√©mon dataset loaded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #       Name Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0  1  Bulbasaur  Grass  Poison    318  45      49       49       65       65   \n",
       "1  2    Ivysaur  Grass  Poison    405  60      62       63       80       80   \n",
       "2  3   Venusaur  Grass  Poison    525  80      82       83      100      100   \n",
       "\n",
       "   Speed  Generation  Legendary  \n",
       "0     45           1      False  \n",
       "1     60           1      False  \n",
       "2     80           1      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/pokedexg13.csv\")\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A)\n",
    "Write a function `kmeans` that takes in a data frame, and uses a predefined distance to run k-means until convergence.  \n",
    "\n",
    "- Check for convergence by calculating the reconstruction error after each step, and stop when the reconstruction error has changed by no more than `tol` from the previous step.\n",
    "- Choose $k$ rows form the data frame at random to be the initial centroids of the clusters\n",
    "\n",
    "Use the in-class notebook code slide, and/or textbook to guide you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.242640687119285"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance = lambda v1, v2: math.pow((math.pow((v2[0]-v1[0]), 2) + math.pow((v2[1]-v1[1]), 2) + math.pow((v2[2]-v1[2]), 2)), 0.5)\n",
    "euclidean_distance([4,2,1], [1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg1 = np.array([2,3,4])\n",
    "arg2 = np.array([1,2,3])\n",
    "arg1 += arg2\n",
    "arg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance():\n",
    "    return distance\n",
    "\n",
    "#parameterized distance function as we will be using a different variant in pt3.\n",
    "def kmeans(df, distance, k=4, tol=0.05): \n",
    "    \"\"\"\n",
    "    Usage: input \n",
    "        df=data frame, \n",
    "        k=# of clusters\n",
    "        tol=tolerance for L_2 convergance check on centroids\n",
    "    \"\"\"    \n",
    "    mean_error = float(\"inf\")\n",
    "    att = df.to_numpy()\n",
    "    #gen init centroids\n",
    "    cent = np.random.choice(len(att), k)\n",
    "    #gets row, hp,att,def per chosen centroid\n",
    "    centroids = [att[x] for x in cent]\n",
    "        \n",
    "    while mean_error > tol:\n",
    "        #distance from centroid\n",
    "        #picking centroids randomly.\n",
    "        #means we run more iterations within loop 2\n",
    "        err = 0\n",
    "        per_cent = [[] for x in range(0,k)] #store point per centroid L of L\n",
    "        for x in range(0, len(att)): #per point - we run O(n*m) iterations n = points, m = centroids.\n",
    "            cent, min_distance = None, float(\"inf\")\n",
    "            for y in range(0, len(centroids)): #per centroid -> we calc distance, therefore we\n",
    "                dist = distance(att[x], centroids[y]) #euclidean distance of (xyz)_1, (xyz)_2\n",
    "                if dist < min_distance:\n",
    "                    min_distance = dist\n",
    "                    cent = y \n",
    "            err += min_distance\n",
    "            per_cent[cent].append(x) \n",
    "        \n",
    "        for x in range(0, len(centroids)): #per centroid\n",
    "            agg_val = np.zeros(3) #use this to aggregate our distance\n",
    "            n = len(per_cent[x]) #this is our 'n' -> number of points.\n",
    "            for y in per_cent[x]: #y corresponds to one point in centroid[x]\n",
    "                    \n",
    "        if mean_error == float(inf):\n",
    "            mean_error = err/n\n",
    "        else:\n",
    "            mean_error = mean_error - err/n \n",
    "            #we take the difference between the error of the previous and the current.\n",
    "            #we want to stop if our change in mean error is less than the tolerance, as that means\n",
    "            #that we are not generating better clusters.\n",
    "            \n",
    "            \n",
    "    return centroids, clusters, meanerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8153. 10535.  9163.]\n",
      "[13951. 19994. 17195.]\n",
      "[20035. 26486. 23103.]\n",
      "[29121. 33417. 31398.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'centroid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-3e269884b46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-7da7c28681d3>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(df, distance, k, tol)\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0magg_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcentroid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;31m#gives us the mean -> [hp/n, att/n, def/n]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m#we have now have our adjusted centroids.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_error\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'centroid' is not defined"
     ]
    }
   ],
   "source": [
    "vals = df.iloc[:, 5:8]\n",
    "kmeans(vals, euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) \n",
    "\n",
    "Use your function to cluster the generation 1-3 Pok√©mon into 4 groups based on their (HP, Attack, Defense) tuples.  Make a scatter plot of the resulting assignments on an (Attack, Defense) axis.\n",
    "\n",
    "Run the function a few times: do you get the exact same clusters every time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C)\n",
    "\n",
    "We need a way to make sure we got the *best* result for  a given value of $k$, and not a particularly unlucky one.  So in practice we usually run kmeans multiple times, and report only the best one.  So re-run your code from part **B** 20 times, and save the assignments/clusters that correspond to the lowest reconstruction error.  Make a scatter plot of the resulting assignments on an (Attack, Defense) axis.\n",
    "\n",
    "*Implementation Idea*: Create a data frame that is 432 rows and 20 columns, fill each column with the results from a \"run\".  Also create a length 20 vectors for the mean reconstruction error of each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D)\n",
    "\n",
    "In parts **A-C** we left $k=4$ as the number of groups.  But we also need to pick the best value of $k$!  Run K-means for $k=1,2,3,\\dots ,10$.\n",
    "- For each value of $k$, run the algorithm at least 10 times with random initialization\n",
    "- For each $k$, select among those runs the one with the *minimum* reconstruction error\n",
    "- Make a plot where $k$ is the $x$-axis and \"best observed reconstruction error\" is the y-axis.\n",
    "\n",
    "Is there a visible \"elbow\" in the plot?  What feels like an appropriate value of $k$, here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p3'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 3 (K-Means and Distance Measures; 18 pts)\n",
    "\n",
    "If you don't know much about Pok√©mon, you should know the following:\n",
    "- Mudkip is the cutest\n",
    "- The \"type\" column matters quite a bit\n",
    "\n",
    "... and we didn't use the \"type\" column!  To do so, we can modify k-means, but it requires us also define a *distance* that we can input types into.  A distance that can be calculated using categories?  Sounds like Jaccard similarity!  Suppose we decide to include the Jaccard distance (recall: it's $1-sim$) in addition to Euclidean distance.  The distance between two Pok√©mon is some combination of the distance between their numeric stats and the distances between their typings, just as in problem **1**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_distance(pokemon1, pokemon2):\n",
    "    #Do the thing\n",
    "    return dist\n",
    "def jacc_distance(pokemon1, pokemon2):\n",
    "    #Do the thing\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $k=4$ and at least 10 runs, cluster the Pok√©mon data set where the distance between two Pok√©mon is the *sum* of their Euclidean ($L_2$) and Jaccard distances.  Represent clusters by their centroids for numeric stats, and by the union of all of their typings for type.  Make a scatter plot of the resulting assignments on an (Attack, Defense) axis.\n",
    "\n",
    "Does it look like typing is mattering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* You can and may want to reformat the data a little, since the two \"Type\" columns don't naturally lend themselves well to being put into a \"set\" for Jaccard computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) \n",
    "\n",
    "Your answer in part **3A** should be \"certainly not!\"  Since Jaccard distances all live in $[0,1]$ and each numerical statistic can range from $[1,256]$, the distances between those stats will totally dominate Jaccard.   But that's no problem!  We can either rescale the *data*, where we shrink stats down to a $[0,1]$ or similar scale, or we can rescale our *distance* to weight some features/columns more than others.  \n",
    "\n",
    "Suppose we decide we want to \"weight\" Jaccard distance $d_J$ as 90% of the calculation and keep the Euclidean stats-distance $d_E$ between Pok√©mon as the remaining 10%.  We could define:\n",
    "\n",
    "$$d(x,y)=.9 d_J(x,y) + .1 d_E(x,y)$$\n",
    "\n",
    "as our distance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_dist(pokemon1, pokemon2, a): #a is the \"percentage\" that we'll weight Jaccard\n",
    "    dist=100*(1-a)*euc_distance(pokemon1, pokemon2)+100*a*jacc_distance(pokemon1, pokemon2)\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using $k=4$ and at least 10 runs, cluster the Pok√©mon data set where the Jaccard distance between Pokemon is given a 99.5% of the weight of the distance function.\n",
    "\n",
    "Make a scatter plot of the resulting assignments on an (Attack, Defense) axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C)\n",
    "\n",
    "Glance over the resulting clusterings in problems 2 and 3.  How would you improve on this method?  Does it appear to be clustering in ways that make sense to you?  If you want a few places to look, consider asking:\n",
    "\n",
    "- Are \"legendary\" Pok√©mon often clustered together?\n",
    "- Are \"starter\" Pok√©mon often clustered together? (These are \\# 1,4,7, 151,155,158,252,255,258)\n",
    "- Should we have used more stats than just (HP, Attack, Defense)?\n",
    "\n",
    "(Nothing specific is looked for here, but show that you explore the data and attempt to sanity check your clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
